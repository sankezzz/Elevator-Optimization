{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import cv2\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "model = YOLO(\"yolov8n.pt\")  # Load YOLOv8 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_people():\n",
    "    # Start capturing video from the default camera\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture video\")\n",
    "            break\n",
    "\n",
    "        # Perform inference\n",
    "        results = model(frame)\n",
    "\n",
    "        # Count the number of people detected (class id for person is usually 0)\n",
    "        person_count = 0\n",
    "        for result in results:\n",
    "            for detection in result.boxes:\n",
    "                if detection.cls == 0:  # Class ID for person\n",
    "                    person_count += 1\n",
    "\n",
    "        # Display the count on the frame\n",
    "        cv2.putText(frame, f'Persons detected: {person_count}', (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        # Show the frame\n",
    "        cv2.imshow('YOLOv8 Person Detection', frame)\n",
    "\n",
    "        # Exit on 'q' key\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 1 cup, 330.0ms\n",
      "Speed: 12.0ms preprocess, 330.0ms inference, 12.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 264.9ms\n",
      "Speed: 0.0ms preprocess, 264.9ms inference, 10.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 181.0ms\n",
      "Speed: 0.0ms preprocess, 181.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 179.3ms\n",
      "Speed: 2.4ms preprocess, 179.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 120.7ms\n",
      "Speed: 0.0ms preprocess, 120.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 104.8ms\n",
      "Speed: 2.2ms preprocess, 104.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 117.5ms\n",
      "Speed: 0.0ms preprocess, 117.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 183.2ms\n",
      "Speed: 3.7ms preprocess, 183.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 189.6ms\n",
      "Speed: 0.0ms preprocess, 189.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 141.5ms\n",
      "Speed: 1.6ms preprocess, 141.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 208.9ms\n",
      "Speed: 0.0ms preprocess, 208.9ms inference, 7.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 229.2ms\n",
      "Speed: 0.0ms preprocess, 229.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 235.1ms\n",
      "Speed: 2.1ms preprocess, 235.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 248.6ms\n",
      "Speed: 0.0ms preprocess, 248.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 240.4ms\n",
      "Speed: 0.0ms preprocess, 240.4ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 158.8ms\n",
      "Speed: 0.0ms preprocess, 158.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.9ms\n",
      "Speed: 1.7ms preprocess, 151.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 207.5ms\n",
      "Speed: 0.0ms preprocess, 207.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 187.6ms\n",
      "Speed: 5.3ms preprocess, 187.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 139.3ms\n",
      "Speed: 2.9ms preprocess, 139.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 197.9ms\n",
      "Speed: 0.0ms preprocess, 197.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 199.2ms\n",
      "Speed: 3.3ms preprocess, 199.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 193.8ms\n",
      "Speed: 0.0ms preprocess, 193.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 179.5ms\n",
      "Speed: 3.8ms preprocess, 179.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 203.8ms\n",
      "Speed: 0.0ms preprocess, 203.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 199.1ms\n",
      "Speed: 0.0ms preprocess, 199.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 210.2ms\n",
      "Speed: 0.0ms preprocess, 210.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 184.3ms\n",
      "Speed: 3.1ms preprocess, 184.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 217.8ms\n",
      "Speed: 0.0ms preprocess, 217.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 208.9ms\n",
      "Speed: 0.0ms preprocess, 208.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 178.0ms\n",
      "Speed: 4.1ms preprocess, 178.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 261.2ms\n",
      "Speed: 6.6ms preprocess, 261.2ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 240.1ms\n",
      "Speed: 0.0ms preprocess, 240.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 230.3ms\n",
      "Speed: 0.0ms preprocess, 230.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 195.4ms\n",
      "Speed: 0.0ms preprocess, 195.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 207.3ms\n",
      "Speed: 0.0ms preprocess, 207.3ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 207.4ms\n",
      "Speed: 0.0ms preprocess, 207.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 143.7ms\n",
      "Speed: 2.3ms preprocess, 143.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 193.0ms\n",
      "Speed: 3.3ms preprocess, 193.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 203.4ms\n",
      "Speed: 0.0ms preprocess, 203.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 184.8ms\n",
      "Speed: 0.0ms preprocess, 184.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 180.0ms\n",
      "Speed: 2.0ms preprocess, 180.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 197.3ms\n",
      "Speed: 0.0ms preprocess, 197.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 195.8ms\n",
      "Speed: 1.0ms preprocess, 195.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 182.5ms\n",
      "Speed: 6.9ms preprocess, 182.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 244.0ms\n",
      "Speed: 0.8ms preprocess, 244.0ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 252.6ms\n",
      "Speed: 0.0ms preprocess, 252.6ms inference, 10.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 176.3ms\n",
      "Speed: 0.0ms preprocess, 176.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 129.5ms\n",
      "Speed: 0.5ms preprocess, 129.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 195.4ms\n",
      "Speed: 0.0ms preprocess, 195.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 223.4ms\n",
      "Speed: 5.3ms preprocess, 223.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 166.6ms\n",
      "Speed: 5.7ms preprocess, 166.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 201.8ms\n",
      "Speed: 0.0ms preprocess, 201.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 187.3ms\n",
      "Speed: 0.0ms preprocess, 187.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 198.6ms\n",
      "Speed: 0.0ms preprocess, 198.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 197.7ms\n",
      "Speed: 0.0ms preprocess, 197.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 208.4ms\n",
      "Speed: 7.2ms preprocess, 208.4ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 199.6ms\n",
      "Speed: 4.3ms preprocess, 199.6ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 202.9ms\n",
      "Speed: 0.0ms preprocess, 202.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 179.9ms\n",
      "Speed: 0.0ms preprocess, 179.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 241.1ms\n",
      "Speed: 0.0ms preprocess, 241.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 227.3ms\n",
      "Speed: 0.0ms preprocess, 227.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 164.5ms\n",
      "Speed: 3.1ms preprocess, 164.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 228.7ms\n",
      "Speed: 4.5ms preprocess, 228.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 231.6ms\n",
      "Speed: 5.3ms preprocess, 231.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 229.3ms\n",
      "Speed: 0.0ms preprocess, 229.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 235.8ms\n",
      "Speed: 0.0ms preprocess, 235.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 242.8ms\n",
      "Speed: 0.0ms preprocess, 242.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 182.5ms\n",
      "Speed: 4.1ms preprocess, 182.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 163.3ms\n",
      "Speed: 2.4ms preprocess, 163.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 201.0ms\n",
      "Speed: 0.0ms preprocess, 201.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 214.1ms\n",
      "Speed: 0.0ms preprocess, 214.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 179.1ms\n",
      "Speed: 2.5ms preprocess, 179.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 225.9ms\n",
      "Speed: 4.5ms preprocess, 225.9ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 vase, 267.3ms\n",
      "Speed: 0.0ms preprocess, 267.3ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 253.2ms\n",
      "Speed: 0.0ms preprocess, 253.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 256.5ms\n",
      "Speed: 0.0ms preprocess, 256.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 252.3ms\n",
      "Speed: 0.0ms preprocess, 252.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 179.2ms\n",
      "Speed: 0.0ms preprocess, 179.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 248.4ms\n",
      "Speed: 1.5ms preprocess, 248.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 250.2ms\n",
      "Speed: 2.6ms preprocess, 250.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 238.1ms\n",
      "Speed: 0.0ms preprocess, 238.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 206.7ms\n",
      "Speed: 3.5ms preprocess, 206.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 221.5ms\n",
      "Speed: 6.6ms preprocess, 221.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 237.7ms\n",
      "Speed: 0.0ms preprocess, 237.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 266.3ms\n",
      "Speed: 0.0ms preprocess, 266.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 249.1ms\n",
      "Speed: 0.0ms preprocess, 249.1ms inference, 16.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 241.7ms\n",
      "Speed: 0.0ms preprocess, 241.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 215.2ms\n",
      "Speed: 2.8ms preprocess, 215.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 273.4ms\n",
      "Speed: 0.0ms preprocess, 273.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 260.6ms\n",
      "Speed: 4.8ms preprocess, 260.6ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 167.7ms\n",
      "Speed: 3.0ms preprocess, 167.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 227.1ms\n",
      "Speed: 0.0ms preprocess, 227.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 207.7ms\n",
      "Speed: 0.0ms preprocess, 207.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 267.8ms\n",
      "Speed: 0.0ms preprocess, 267.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 254.8ms\n",
      "Speed: 3.5ms preprocess, 254.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 268.2ms\n",
      "Speed: 0.0ms preprocess, 268.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 193.1ms\n",
      "Speed: 2.8ms preprocess, 193.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 229.4ms\n",
      "Speed: 3.1ms preprocess, 229.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 281.0ms\n",
      "Speed: 0.0ms preprocess, 281.0ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 223.8ms\n",
      "Speed: 0.0ms preprocess, 223.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 173.2ms\n",
      "Speed: 3.7ms preprocess, 173.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 227.0ms\n",
      "Speed: 0.0ms preprocess, 227.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 224.0ms\n",
      "Speed: 0.0ms preprocess, 224.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 247.1ms\n",
      "Speed: 5.6ms preprocess, 247.1ms inference, 11.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 219.0ms\n",
      "Speed: 5.0ms preprocess, 219.0ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 171.8ms\n",
      "Speed: 2.8ms preprocess, 171.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    detect_people()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  Invalid export format='torch', updating to format='torchscript'\n",
      "Ultralytics 8.3.16  Python-3.12.2 torch-2.4.1+cpu CPU (12th Gen Intel Core(TM) i5-1240P)\n",
      "YOLOv8n summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.4.1+cpu...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  3.3s, saved as 'yolov8n.torchscript' (12.5 MB)\n",
      "\n",
      "Export complete (4.3s)\n",
      "Results saved to \u001b[1mC:\\Users\\sanke\\OneDrive\\Desktop\\Lift management\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8n.torchscript imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolov8n.torchscript imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolov8n.torchscript'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the model\n",
    "model = YOLO(\"yolov8n.pt\")  # Replace with your model path if needed\n",
    "\n",
    "# Export the model\n",
    "model.export(format=\"torch\")  # This will save your model in .pt format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
